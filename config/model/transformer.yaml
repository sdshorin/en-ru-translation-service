name: transformer

pad_token_id: null
vocab_size: null

model_info:
  _target_: src.models.transformer.Transformer
  vocab_size: ${model.vocab_size}
  d_model: 512
  nhead: 4
  num_encoder_layers: 5
  num_decoder_layers: 5
  dim_feedforward: 1024
  dropout: 0.1
  max_seq_length: 64
  tokenizer_name: ${data.tokenizer.name}

encoder:
  vocab_size: ${model.vocab_size}
decoder:
  vocab_size: ${model.vocab_size}
